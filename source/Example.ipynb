{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training a neural network using a modified version of the VAE network. By elmininating the KL divergence term on the loss function and setting epsilon equal to zero, we arrive at an autoencoder network that reconstructs hand-written digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt \n",
    "# from VAE import VAE\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class VAE(object):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, params):\n",
    "        '''intializes weights matrix and parameters'''\n",
    "\n",
    "        # initialize size of VAE \n",
    "        self.encoder_layer_sizes = input_dim + [2]\n",
    "        self.decoder_layer_sizes = [2, 1] + output_dim[::-1] \n",
    "        self.total_layer_sizes   = input_dim + [2, 1] + output_dim[::-1]\n",
    "       \n",
    "        self.number_encoder_layers = len(self.encoder_layer_sizes) - 1\n",
    "        self.number_decoder_layers = len(self.decoder_layer_sizes) - 1\n",
    "        self.number_total_layers   = len(self.total_layer_sizes) - 1\n",
    "\n",
    "        # intialize weights\n",
    "        self.encoder_weights = {}\n",
    "        for i in range(self.number_encoder_layers):\n",
    "            self.encoder_weights[i] = np.random.uniform(-0.1, 0.1, \n",
    "                                                        (self.encoder_layer_sizes[i], \n",
    "                                                         self.encoder_layer_sizes[i+1])) \n",
    "        self.decoder_weights = {}\n",
    "        for i in range(self.number_decoder_layers):\n",
    "            self.decoder_weights[i] = np.random.uniform(-0.1, 0.1, \n",
    "                                                        (self.decoder_layer_sizes[i],\n",
    "                                                         self.decoder_layer_sizes[i+1]))\n",
    "        # set params\n",
    "        self.alpha = params['alpha']\n",
    "        self.max_iter = params['max_iter']\n",
    "        self.activation = params['activation']\n",
    "        self.grad_activation = params['grad_act']\n",
    "        self.loss = params['loss']\n",
    "        self.grad_loss = params['grad_loss']\n",
    "\n",
    "    def train(self, train_data):\n",
    "        '''trains the VAE model'''\n",
    "        count = 0\n",
    "        while count < self.max_iter:   \n",
    "            \n",
    "            # feed forward network\n",
    "            yhat = self.feedforward(train_data)\n",
    "            \n",
    "            # backpropogate errors\n",
    "            grad_encoder, grad_decoder = self.backprop(train_data, yhat)\n",
    "        \n",
    "            # update weights with gradient descent\n",
    "            for i in range(self.number_decoder_layers):\n",
    "                self.decoder_weights[i] -= self.alpha * grad_decoder[i]\n",
    "                \n",
    "            for i in range(self.number_encoder_layers):\n",
    "                self.encoder_weights[i] -= self.alpha * grad_encoder[i]\n",
    "                \n",
    "            count += 1\n",
    "            \n",
    "        return None\n",
    "\n",
    "    def predict(self, train_data):\n",
    "        '''predicts on a trained VAE model'''        \n",
    "        yhat = self.feedforward(train_data)\n",
    "        return yhat\n",
    "    \n",
    "    def generate(self):\n",
    "        '''generates new images from a trained VAE model'''        \n",
    "        \n",
    "        # sample from latent variable space\n",
    "        \n",
    "        # feedforward on decoder\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def KLD(self):\n",
    "        '''Kullbackâ€“Leibler divergence loss'''\n",
    "        pass\n",
    "\n",
    "    def backprop(self, y, yhat):\n",
    "        '''back-propagation algorithm'''\n",
    "        # initialize \n",
    "        grad_decoder = {}\n",
    "        grad_encoder = {}\n",
    "    \n",
    "        # backpropogate error through decoder layers\n",
    "        rev_range = np.arange(self.number_decoder_layers)[::-1]\n",
    "        n = rev_range[0]\n",
    "        \n",
    "        delta = - self.grad_loss(y, yhat) * self.grad_activation(self.decoder_input[n])\n",
    "        grad_decoder[n] = self.decoder_activation[n-1].T @ delta\n",
    "        \n",
    "        for i in rev_range[1:-1]:\n",
    "            delta = delta @ self.decoder_weights[i+1].T * self.grad_activation(self.decoder_input[i])\n",
    "            grad_decoder[i] = self.decoder_activation[i-1].T @ delta \n",
    "            \n",
    "        # backpropogate errors through encoder layers\n",
    "        rev_range = np.arange(self.number_encoder_layers)[::-1]\n",
    "        n = rev_range[0]\n",
    "        \n",
    "        delta = delta @ self.decoder_weights[1].T * self.grad_activation(self.decoder_input[0])\n",
    "        grad_decoder[0] = self.encoder_activation[1].T @ delta\n",
    "        \n",
    "        delta = delta @ self.decoder_weights[0].T * self.grad_activation(self.encoder_input[n])\n",
    "        grad_encoder[n] = self.encoder_activation[0].T @ delta\n",
    "        \n",
    "        for i in rev_range[1:-1]:\n",
    "            delta = delta @ self.encoder_weights[i+1].T * self.grad_activation(self.encoder_input[i])\n",
    "            grad_encoder[i] = self.encoder_activation[i-1].T @ delta\n",
    "        \n",
    "        delta = delta @ self.encoder_weights[1].T * self.grad_activation(self.encoder_input[0])\n",
    "        grad_encoder[0] = y.T @ delta\n",
    "    \n",
    "        return grad_encoder, grad_decoder \n",
    "            \n",
    "    def feedforward(self, train_data):\n",
    "        '''feedforward update step'''\n",
    "        \n",
    "        # initialize storage for activations\n",
    "        self.encoder_input = {}\n",
    "        self.encoder_activation = {}\n",
    "        self.decoder_input = {}\n",
    "        self.decoder_activation = {}\n",
    "        \n",
    "        self.encoder_input[0]      = train_data @ self.encoder_weights[0]\n",
    "        self.encoder_activation[0] = self.activation(self.encoder_input[0])\n",
    "            \n",
    "        # feedforward update on encoder network\n",
    "        for i in range(1, self.number_encoder_layers):\n",
    "            self.encoder_input[i] = self.encoder_input[i-1] @ self.encoder_weights[i]\n",
    "            self.encoder_activation[i] = self.activation(self.encoder_input[i])\n",
    "        \n",
    "        # store output as encoded latent variable parameters\n",
    "        \n",
    "        self.mu = self.encoder_activation[i][:,1]\n",
    "        self.sigma = self.encoder_activation[i][:,0]\n",
    "        \n",
    "        # sample latent variable using reparameterization trick\n",
    "        self.z = np.array((self.mu.T, self.sigma.T)) \n",
    "        \n",
    "        # feedforward update on the decoder network\n",
    "        self.decoder_input[0]      = self.z.T @ self.decoder_weights[0]\n",
    "        self.decoder_activation[0] = self.activation(self.decoder_input[0])\n",
    "        \n",
    "        for i in range(1, self.number_decoder_layers):\n",
    "            self.decoder_input[i] = self.decoder_input[i-1] @ self.decoder_weights[i]\n",
    "            self.decoder_activation[i] = self.activation(self.decoder_input[i])\n",
    "\n",
    "        return self.decoder_activation[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we import the VAE class, we set up the parameters and intialize the weights. The loss function is the squared error and the activation function is the sigmoid. As part of backpropogation, we also need to pass in the derviative of the loss and activation. \n",
    "\n",
    "$$Loss(y, \\hat{y}) = \\sum (y - \\hat{y})^2$$\n",
    "$$\\sigma(x) = \\frac{1}{1 + exp(-x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha' : 0.1,\n",
    "    'max_iter' : 75,\n",
    "    'activation' : (lambda x: 1 / (1 + np.exp(-x))),\n",
    "    'grad_act' : (lambda x: np.exp(-x) / (1 + np.exp(-x))**2),\n",
    "    'loss' : (lambda y, yhat: 0.5 * np.sum((y - yhat)**2)),\n",
    "    'grad_loss' : (lambda y, yhat: y - yhat)\n",
    "}\n",
    "\n",
    "example = VAE([64, 20], [64, 20], params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pass a training digit of size 8 by 8 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iI4gMJUXwgof8A4C6Y4wlBav8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ff69af748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_digit = np.array((digits.data[0][None,:])) / 256\n",
    "plt.matshow(in_digit.reshape((8,8)), cmap='gray')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intialize the weights to be random, so the first pass looks jumbled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ff69af2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_digit = example.feedforward(in_digit)\n",
    "plt.matshow(out_digit.reshape((8,8)), cmap = 'gray')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the network to reduce the loss function and reproduce the training image. Here are the reconstructed images after each 75 training interations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAywAAADMCAYAAACRIieCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbLGwAAAAAMgWCwsAAACAbP0vcYA85sIq0XYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ff68126d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,4, figsize = (14, 10))\n",
    "\n",
    "example.train(in_digit)\n",
    "pred1 = example.predict(in_digit)\n",
    "ax[0].matshow(pred1.reshape((8,8)), cmap='gray')\n",
    "\n",
    "example.train(in_digit)\n",
    "pred2 = example.predict(in_digit)\n",
    "ax[1].matshow(pred2.reshape((8,8)), cmap='gray')\n",
    "\n",
    "example.train(in_digit)\n",
    "pred3 = example.predict(in_digit)\n",
    "ax[2].matshow(pred3.reshape((8,8)), cmap='gray')\n",
    "\n",
    "example.train(in_digit)\n",
    "pred4 = example.predict(in_digit)\n",
    "ax[3].matshow(pred4.reshape((8,8)), cmap='gray')\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
