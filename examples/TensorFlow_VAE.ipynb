{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "mnist = read_data_sets('MNIST_data', one_hot=True)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval=low, maxval=high, \n",
    "                             dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    \n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian \n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "    \n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture, transfer_fct=tf.nn.softplus, \n",
    "                 learning_rate=0.001, batch_size=100):\n",
    "        self.network_architecture = network_architecture\n",
    "        self.transfer_fct = transfer_fct\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, [None, network_architecture[\"n_input\"]])\n",
    "        \n",
    "        # Create autoencoder network\n",
    "        self._create_network()\n",
    "        # Define loss function based variational upper-bound and \n",
    "        # corresponding optimizer\n",
    "        self._create_loss_optimizer()\n",
    "        \n",
    "        # Initializing the tensor flow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "    \n",
    "    def _create_network(self):\n",
    "        # Initialize autoencode network weights and biases\n",
    "        network_weights = self._initialize_weights(**self.network_architecture)\n",
    "\n",
    "        # Use recognition network to determine mean and \n",
    "        # (log) variance of Gaussian distribution in latent\n",
    "        # space\n",
    "        self.z_mean, self.z_log_sigma_sq = self._recognition_network(network_weights[\"weights_recog\"], \n",
    "                                      network_weights[\"biases_recog\"])\n",
    "\n",
    "        # Draw one sample z from Gaussian distribution\n",
    "        n_z = self.network_architecture[\"n_z\"]\n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        # z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.sqrt(tf.exp(self.z_log_sigma_sq))*eps)\n",
    "\n",
    "        # Use generator to determine mean of\n",
    "        # Bernoulli distribution of reconstructed input\n",
    "        self.x_reconstr_mean = self._generator_network(network_weights[\"weights_gener\"],\n",
    "                                    network_weights[\"biases_gener\"])\n",
    "            \n",
    "    def _initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        all_weights = dict()\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "            \n",
    "    def _recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean'])\n",
    "        z_log_sigma_sq = tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "\n",
    "    def _generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto a Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        x_reconstr_mean = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))\n",
    "        return x_reconstr_mean\n",
    "            \n",
    "    def _create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        reconstr_loss = -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           1)\n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n",
    "                                           - tf.square(self.z_mean) \n",
    "                                           - tf.exp(self.z_log_sigma_sq), 1)\n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "        # Use ADAM optimizer\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=5):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Fit training using batch data\n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 186.809721347\n"
     ]
    }
   ],
   "source": [
    "network_architecture = \\\n",
    "    dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=200, # 2nd layer encoder neurons\n",
    "         n_hidden_gener_1=200, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "         n_input=784, # MNIST data input (img shape: 28*28)\n",
    "         n_z=2)  # dimensionality of latent space\n",
    "\n",
    "vae = train(network_architecture, training_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAFICAYAAAC1E/PEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkC0mwwAAAMjW/wNSbL4zc/MZ0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba00020630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sample = mnist.test.next_batch(100)[0]\n",
    "x_reconstruct = vae.reconstruct(x_sample)\n",
    "\n",
    "fig, ax = plt.subplots(2,5, figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    ax[0,i].imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    ax[1,i].imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. [Variational Autoencoders in TensorFlow](https://jmetzen.github.io/2015-11-27/vae.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
