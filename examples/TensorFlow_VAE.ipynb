{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "mnist = read_data_sets('MNIST_data', one_hot=True)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval=low, maxval=high, \n",
    "                             dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    \n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian \n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "    \n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture, transfer_fct=tf.nn.softplus, \n",
    "                 learning_rate=0.001, batch_size=100):\n",
    "        self.network_architecture = network_architecture\n",
    "        self.transfer_fct = transfer_fct\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, [None, network_architecture[\"n_input\"]])\n",
    "        \n",
    "        # Create autoencoder network\n",
    "        self._create_network()\n",
    "        # Define loss function based variational upper-bound and \n",
    "        # corresponding optimizer\n",
    "        self._create_loss_optimizer()\n",
    "        \n",
    "        # Initializing the tensor flow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "    \n",
    "    def _create_network(self):\n",
    "        # Initialize autoencode network weights and biases\n",
    "        network_weights = self._initialize_weights(**self.network_architecture)\n",
    "\n",
    "        # Use recognition network to determine mean and \n",
    "        # (log) variance of Gaussian distribution in latent\n",
    "        # space\n",
    "        self.z_mean, self.z_log_sigma_sq = self._recognition_network(network_weights[\"weights_recog\"], \n",
    "                                      network_weights[\"biases_recog\"])\n",
    "\n",
    "        # Draw one sample z from Gaussian distribution\n",
    "        n_z = self.network_architecture[\"n_z\"]\n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        # z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.sqrt(tf.exp(self.z_log_sigma_sq))*eps)\n",
    "\n",
    "        # Use generator to determine mean of\n",
    "        # Bernoulli distribution of reconstructed input\n",
    "        self.x_reconstr_mean = self._generator_network(network_weights[\"weights_gener\"],\n",
    "                                    network_weights[\"biases_gener\"])\n",
    "            \n",
    "    def _initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        all_weights = dict()\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "            \n",
    "    def _recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean'])\n",
    "        z_log_sigma_sq = tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "\n",
    "    def _generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto a Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        x_reconstr_mean = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))\n",
    "        return x_reconstr_mean\n",
    "            \n",
    "    def _create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        reconstr_loss = -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           1)\n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n",
    "                                           - tf.square(self.z_mean) \n",
    "                                           - tf.exp(self.z_log_sigma_sq), 1)\n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "        # Use ADAM optimizer\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=5):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # Fit training using batch data\n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 190.358352217\n"
     ]
    }
   ],
   "source": [
    "network_architecture = \\\n",
    "    dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=200, # 2nd layer encoder neurons\n",
    "         n_hidden_gener_1=200, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "         n_input=784, # MNIST data input (img shape: 28*28)\n",
    "         n_z=2)  # dimensionality of latent space\n",
    "\n",
    "vae = train(network_architecture, training_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAFICAYAAAC1E/PEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x170240bd978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_sample = mnist.test.next_batch(100)[0]\n",
    "x_reconstruct = vae.reconstruct(x_sample)\n",
    "\n",
    "fig, ax = plt.subplots(2,5, figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    ax[0,i].imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    ax[1,i].imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "1. [Xavier initialization](https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow)\n",
    "2. [Variational Autoencoder in TensorFlow](https://jmetzen.github.io/2015-11-27/vae.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
